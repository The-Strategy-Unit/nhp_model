{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Hospitals Model\n",
    "\n",
    "This notebook runs the NHP model and produces the aggregated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file = \"sample_params.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from model.aae import AaEModel\n",
    "from model.inpatients import InpatientsModel\n",
    "from model.outpatients import OutpatientsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a folder ready to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/synthetic/results/test/20220412_102757/params.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(params_file, \"r\", encoding=\"UTF-8\") as pf:\n",
    "  params = json.load(pf)\n",
    "\n",
    "dataset = params[\"input_data\"]\n",
    "scenario = params[\"name\"]\n",
    "model_runs = params[\"model_runs\"]\n",
    "\n",
    "run_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "results_path = f\"data/{dataset}/results/{scenario}/{run_time}\"\n",
    "\n",
    "os.makedirs(results_path)\n",
    "shutil.copy(params_file, f\"{results_path}/params.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the model in parallel. By default, use all available CPU cores. You can set this to a lower value to use less resources, but it will take longer to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpus = os.cpu_count()\n",
    "cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the model in parallel it's slightly more efficient to run a batch of model runs. Batches of 4 or 8 seems to be most efficient. This value should be a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2 ** 2\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [00:24, 10.82it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model runs completed: 257 / 257\n"
     ]
    }
   ],
   "source": [
    "(AaEModel(results_path)\n",
    "# add 1 because of the principal run\n",
    "  .multi_model_runs(0, model_runs + 1, cpus, batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [00:39,  6.61it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model runs completed: 257 / 257\n"
     ]
    }
   ],
   "source": [
    "(OutpatientsModel(results_path)\n",
    "  .multi_model_runs(0, model_runs + 1, cpus, batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:59,  2.18it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model runs completed: 257 / 257\n"
     ]
    }
   ],
   "source": [
    "(InpatientsModel(results_path)\n",
    "  .multi_model_runs(0, model_runs + 1, cpus, batch_size)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71037dceb37210055783f0299c3deef8fe179ebbcc2d71658480775f1f49bb03"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nhp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
