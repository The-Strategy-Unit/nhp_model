{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thomas.jemmett\\dev\\nhp\\nhp_model\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Hospitals Model\n",
    "\n",
    "This notebook runs the NHP model and produces the raw results.\n",
    "\n",
    "Note, this can take a very long time to run and load the resulting data. If you find that you are running out of RAM (especially when loading data) consider reducing the number of model runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file = \"sample_params.json\"\n",
    "data_path = \"data\"\n",
    "results_path = \"results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from run_model import run_model\n",
    "\n",
    "from model.aae import AaEModel\n",
    "from model.inpatients import InpatientsModel\n",
    "from model.outpatients import OutpatientsModel\n",
    "from model.model_save import LocalSave\n",
    "from model.helpers import load_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load in the params json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_params(params_file)\n",
    "# extract the number of model_runs the params calls for\n",
    "model_runs = params[\"model_runs\"]\n",
    "# get the dataset name\n",
    "dataset = params[\"input_data\"]\n",
    "# and get the scenario\n",
    "scenario = params[\"name\"]\n",
    "# set the create_datetime\n",
    "create_datetime = params[\"create_datetime\"] = f\"{datetime.now():%Y%m%d_%H%M%S}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the model in parallel. By default, use all available CPU cores. You can set this to a lower value to use less resources, but it will take longer to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = os.cpu_count()\n",
    "cpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the model in parallel it's slightly more efficient to run a batch of model runs. Batches of 4 or 8 seems to be most efficient. This value should be a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 ** 2\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the model runner. The `run_model()` function expects the params dictionary, the path to the data, the path where the results will be saved, which model run to start at, how many model runs to perform, the number of CPU cores to use, and the size of the batches to run.\n",
    "\n",
    "The function returns a function, which takes either `AaEModel`, `InpatientsModel`, or `OutpatientsModel`, depending on what type of model we want to run.\n",
    "\n",
    "Note, we add one to the model runs. The \"principal\" model run is model run 0, and then we perform 1 to `model_runs` iterations of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = LocalSave(params, results_path, temppath:=tempfile.mkdtemp(), True)\n",
    "runner = run_model(model_save, -1, model_runs + 2, cpus, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the runner is set up, we can run each of the types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in [AaEModel, OutpatientsModel, InpatientsModel]:\n",
    "    runner(m(params, \"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with all of the models run, we can now call the `post_runs()` method which will save the params/run params/change factors and aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save.post_runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load in our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(activity_type):\n",
    "  base_data = (pq\n",
    "    .read_pandas(f\"data/{dataset}/{activity_type}.parquet\")\n",
    "    .to_pandas()\n",
    "  )\n",
    "  results_data = (pq\n",
    "    .ParquetDataset(\n",
    "      f\"{results_path}/model_results/activity_type={activity_type}/\" +\n",
    "      f\"dataset={dataset}/scenario={scenario}/create_datetime={create_datetime}\"\n",
    "    )\n",
    "    .read_pandas()\n",
    "    .to_pandas()\n",
    "  )\n",
    "  base_data_cols = [col\n",
    "    for col in (base_data.columns)\n",
    "    if col not in set(results_data.columns)\n",
    "  ]\n",
    "  # fix category columns\n",
    "  results_data[\"model_run\"] = results_data[\"model_run\"].astype(int)\n",
    "  # merge and return\n",
    "  return (base_data[base_data_cols]\n",
    "    .merge(results_data, left_on = \"rn\", right_index = True)\n",
    "    .drop(\"rn\", axis=\"columns\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = load_dataset(\"aae\")\n",
    "aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = load_dataset(\"ip\")\n",
    "ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "op data needs to be handled slightly differently: we need to add in the op conversion rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_op_data():\n",
    "  grouping_cols = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"tretspef\",\n",
    "    \"is_gp_ref\",\n",
    "    \"is_cons_cons_ref\",\n",
    "    \"is_first\",\n",
    "    \"has_procedures\",\n",
    "    \"model_run\"\n",
    "  ]\n",
    "  # load the ip->op conversion data\n",
    "  base_data = (pq\n",
    "    .read_pandas(f\"data/{dataset}/ip.parquet\")\n",
    "    .to_pandas()\n",
    "  )\n",
    "  results_data = (pq\n",
    "    .ParquetDataset(\n",
    "      f\"{results_path}/model_results/activity_type=op_conversion/\" +\n",
    "      f\"dataset={dataset}/scenario={scenario}/create_datetime={create_datetime}\")\n",
    "    .read_pandas()\n",
    "    .to_pandas()\n",
    "  )\n",
    "  base_data_cols = [col\n",
    "    for col in (base_data.columns)\n",
    "    if col not in set(results_data.columns)\n",
    "  ]\n",
    "  grouping_cols_subset = [\n",
    "    i for i in grouping_cols if i in set(base_data_cols) or i in set(results_data.columns)\n",
    "  ]\n",
    "  # fix category columns\n",
    "  results_data[\"model_run\"] = results_data[\"model_run\"].astype(int)\n",
    "  # merge results and aggregate\n",
    "  merged = (base_data[base_data_cols]\n",
    "    .merge(results_data, left_on = \"rn\", right_index = True)\n",
    "    .groupby(grouping_cols_subset)\n",
    "    .agg({\"attendances\": \"sum\", \"tele_attendances\": \"sum\"})\n",
    "    .assign(is_gp_ref = False, is_cons_cons_ref = False, is_first = False, has_procedures = True)\n",
    "    .reset_index()\n",
    "  )\n",
    "  # load the op data\n",
    "  op = load_dataset(\"op\")[grouping_cols + [\"attendances\", \"tele_attendances\"]]\n",
    "  # combine the data\n",
    "  return (pd\n",
    "    .concat([op, merged])\n",
    "    .groupby(grouping_cols)\n",
    "    .agg({\"attendances\": \"sum\", \"tele_attendances\": \"sum\"})\n",
    "    .reset_index()\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = load_op_data()\n",
    "op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can load the change factors in like so. Note, the order of the rows is semi-important within each model_run:\n",
    "the \"baseline\" change_factor row must always come first. The other rows are then in the order that change factor\n",
    "was run within the model engine, but strictly do not need to be shown in that order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_factors = pd.read_csv(\n",
    "  f\"{results_path}/change_factors/{dataset}__{scenario}__{create_datetime}.csv\"\n",
    ")\n",
    "change_factors"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6517ca32f8fc9ce26110ffab86f836252d161f988376f7559d29b21e62e92b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nhp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
